{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import dataloader\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import torch.optim as optim\n",
    "\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.common_fcns import *\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_name</th>\n",
       "      <th>slice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file_brain_AXT2_200_2000535_0</td>\n",
       "      <td>[1.0057089e-05, 9.772637e-06, 1.2455052e-05, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file_brain_AXT2_200_2000535_1</td>\n",
       "      <td>[1.37167e-05, 1.5023721e-05, 1.3295172e-05, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file_brain_AXT2_200_2000535_2</td>\n",
       "      <td>[1.39793265e-05, 2.2203161e-05, 1.8096427e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file_brain_AXT2_200_2000535_3</td>\n",
       "      <td>[1.4201461e-05, 1.3245278e-05, 1.45633185e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file_brain_AXT2_200_2000535_4</td>\n",
       "      <td>[6.0453976e-06, 9.784446e-06, 7.2580615e-06, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>file_brain_AXT2_200_2000368_11</td>\n",
       "      <td>[5.3172553e-06, 5.5633427e-06, 6.050383e-06, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>file_brain_AXT2_200_2000368_12</td>\n",
       "      <td>[6.7074516e-06, 6.0870066e-06, 8.798891e-06, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>file_brain_AXT2_200_2000368_13</td>\n",
       "      <td>[7.124069e-06, 7.744692e-06, 7.642781e-06, 4.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>file_brain_AXT2_200_2000368_14</td>\n",
       "      <td>[7.2822577e-06, 5.6842214e-06, 6.9956786e-06, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>file_brain_AXT2_200_2000368_15</td>\n",
       "      <td>[5.5472374e-06, 9.395522e-06, 6.01025e-06, 6.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         slice_name  \\\n",
       "0     file_brain_AXT2_200_2000535_0   \n",
       "1     file_brain_AXT2_200_2000535_1   \n",
       "2     file_brain_AXT2_200_2000535_2   \n",
       "3     file_brain_AXT2_200_2000535_3   \n",
       "4     file_brain_AXT2_200_2000535_4   \n",
       "..                              ...   \n",
       "425  file_brain_AXT2_200_2000368_11   \n",
       "426  file_brain_AXT2_200_2000368_12   \n",
       "427  file_brain_AXT2_200_2000368_13   \n",
       "428  file_brain_AXT2_200_2000368_14   \n",
       "429  file_brain_AXT2_200_2000368_15   \n",
       "\n",
       "                                                 slice  \n",
       "0    [1.0057089e-05, 9.772637e-06, 1.2455052e-05, 1...  \n",
       "1    [1.37167e-05, 1.5023721e-05, 1.3295172e-05, 1....  \n",
       "2    [1.39793265e-05, 2.2203161e-05, 1.8096427e-05,...  \n",
       "3    [1.4201461e-05, 1.3245278e-05, 1.45633185e-05,...  \n",
       "4    [6.0453976e-06, 9.784446e-06, 7.2580615e-06, 7...  \n",
       "..                                                 ...  \n",
       "425  [5.3172553e-06, 5.5633427e-06, 6.050383e-06, 7...  \n",
       "426  [6.7074516e-06, 6.0870066e-06, 8.798891e-06, 6...  \n",
       "427  [7.124069e-06, 7.744692e-06, 7.642781e-06, 4.7...  \n",
       "428  [7.2822577e-06, 5.6842214e-06, 6.9956786e-06, ...  \n",
       "429  [5.5472374e-06, 9.395522e-06, 6.01025e-06, 6.0...  \n",
       "\n",
       "[430 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment the below line if you haven't created the dataset file yet\n",
    "#!python prepare_training_data.py \n",
    "\n",
    "# Load in the data file\n",
    "df = pd.read_pickle('../data/training_set_true_image.pkl')\n",
    "display(df)\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(Data, self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "train_slices = df['slice'].to_numpy()\n",
    "data = Data(train_slices,train_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inherit from torch.nn, define basic k-latent AutoEncoder\n",
    "k_latent = 3000\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.k_latent_encode = nn.Linear(256*256, k_latent)\n",
    "        self.k_latent_decode = nn.Linear(k_latent, 256*256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.k_latent_encode(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.k_latent_decode(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "n_epochs = 100\n",
    "minibatch_size = 429 #Full batch\n",
    "batch_loss = np.zeros(n_epochs)\n",
    "\n",
    "model = AutoEncoder()\n",
    "#model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=100000)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch: 0 , Loss: 0.345411092042923\n",
      "Completed epoch: 1 , Loss: 3.7955553366941785e-08\n"
     ]
    }
   ],
   "source": [
    "# Do training\n",
    "for epoch in range(n_epochs):\n",
    "    # Pick batches for this epoch\n",
    "    train_loader = torch.utils.data.DataLoader(data, batch_size=minibatch_size, shuffle=True)\n",
    "    for batch_idx, (X, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        Y = model(X)\n",
    "        loss = criterion(X,Y)\n",
    "        batch_loss[epoch]+=loss.item() # save off the loss\n",
    "        loss.backward()\n",
    "        optimizer.step()    # update\n",
    "    print(\"Completed epoch: \"+str(epoch)+\" , Loss: \"+str(batch_loss[epoch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a scan in\n",
    "data_dir = '../data/multicoil_test/'\n",
    "file = data_dir+'file_brain_AXT2_200_2000482.h5'\n",
    "hf = h5py.File(file)\n",
    "volume_kspace = hf['kspace'][()]\n",
    "n_slices = volume_kspace.shape[0]\n",
    "X_raw = combine_all_coils(volume_kspace,8)\n",
    "X = resize_scan(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it through our autoencoder and see what we get!\n",
    "X_input = torch.from_numpy(X.flatten())\n",
    "X_output = model(X_input)\n",
    "X_output = X_output.detach().numpy().reshape(256,256)\n",
    "plt.imshow(np.abs(X_output), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
